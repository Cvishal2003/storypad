# Voice Journal Feature - Technical Overview

## ğŸ’° Feature Pricing: $1.99 (One-time purchase)

---

## âœ… Status: COMPLETE & SHIPPED ğŸš€

The Voice Journaling feature is fully implemented and live in production! Users can record voice notes, organize them by tags, and play them back seamlessly.

---

## ğŸ“ Architecture

### Asset System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Story Content (Quill Editor)          â”‚
â”‚  â€¢ BlockEmbed.image() âœ…               â”‚
â”‚  â€¢ BlockEmbed.audio() â† NEW            â”‚
â”‚  â€¢ BlockEmbed.date()                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AssetDbModel (Application Layer)      â”‚
â”‚  âœ… type: 'image' | 'audio'            â”‚
â”‚  âœ… metadata: Map<String, dynamic>     â”‚
â”‚  âœ… isAudio, isImage (getters)         â”‚
â”‚  âœ… durationInMs, formattedDuration    â”‚
â”‚  âœ… link (storypad://audio/id)         â”‚
â”‚  âœ… downloadFilePath (routes audio/)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         (JSON Encoding/Decoding)
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AssetObjectBox (Database Layer)       â”‚
â”‚  âœ… type: String? ('image', 'audio')   â”‚
â”‚  âœ… metadata: String? (JSON)           â”‚
â”‚  â€¢ originalSource                      â”‚
â”‚  â€¢ cloudDestinations                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
         ObjectBox Storage
```

---

## ğŸ“ File Storage

```
Device Storage:
  kSupportDirectory/
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ 1701234567890.jpg     âœ… Existing
    â”‚   â””â”€â”€ 1701234567891.jpeg
    â””â”€â”€ audio/                     âœ… NEW
        â”œâ”€â”€ 1701234568000.m4a      Voice recordings
        â”œâ”€â”€ 1701234568001.m4a
        â””â”€â”€ 1701234568002.m4a

Google Drive Backup:
  Same directory structure, automatic sync
```

---

## ğŸ“ Implemented Changes

### 0. **AssetType Enum** (`lib/core/types/asset_type.dart`) âœ¨ NEW

Central type system for all asset types with built-in URI and storage path management:

```dart
enum AssetType {
  image(embedLinkPath: 'assets', subDirectory: 'images'),
  audio(embedLinkPath: 'audio', subDirectory: 'audio');

  final String embedLinkPath;  // URI scheme path
  final String subDirectory;    // Storage directory name

  // URI prefix: "storypad://assets/" or "storypad://audio/"
  String get embedLinkPrefix => 'storypad://$embedLinkPath/';

  // Build complete link: "storypad://audio/123"
  String buildEmbedLink(int id) => '$embedLinkPrefix$id';

  // Get storage path: "/support/audio/123.m4a"
  String getStoragePath({required int id, required String extension});

  // Parse ID from link: "storypad://audio/123" â†’ 123
  int? parseAssetIdFromLink(String link);

  // Static helpers
  static int? parseAssetId(String link);  // Works with any type
  static AssetType? getTypeFromLink(String link);
  static bool isValidAssetLink(String link);  // Check if string is valid asset link
  static List<String> get allEmbedLinkPrefixes;  // All supported URI schemes
  static AssetType fromValue(String? value);  // For JSON
}
```

**Benefits:**

- Single source of truth for asset type configuration
- Type-safe enum instead of string constants
- Automatic URI scheme and storage path generation
- Easy to add new asset types (just add enum value)
- Backward compatible with existing image links

### 1. **AssetObjectBox** (`lib/core/databases/adapters/objectbox/entities.dart`)

```dart
@Entity()
class AssetObjectBox extends BaseObjectBox {
  String? type;       // 'image', 'audio', etc.
  String? metadata;   // JSON string for flexible metadata
}
```

### 2. **AssetDbModel** (`lib/core/databases/models/asset_db_model.dart`)

```dart
class AssetDbModel extends BaseDbModel {
  final AssetType type;  // Enum: AssetType.image | AssetType.audio
  final Map<String, dynamic>? metadata;

  // Getters
  bool get isAudio => type == AssetType.audio;
  bool get isImage => type == AssetType.image;
  int? get durationInMs => metadata?['duration_in_ms'] as int?;
  String? get formattedDuration; // Returns "MM:SS" format

  // Smart link routing using AssetType enum
  String get embedLink => type.buildEmbedLink(id);
  // Returns: "storypad://audio/123" or "storypad://assets/123"

  // Helper for storage path (delegates to AssetType)
  String get localFilePath {
    return type.getStoragePath(
      id: id,
      extension: extension(originalSource),
    );
  }

  // Create audio asset with duration
  static AssetDbModel fromLocalPath({
    required int id,
    required String localPath,
    required AssetType type,  // Required enum type
    int? durationInMs,
  }) { ... }

  // Update duration later
  AssetDbModel copyWithDuration(int durationInMs) { ... }

  // Find asset by URI link (uses AssetType.parseAssetId)
  static Future<AssetDbModel?> findBy({
    required String embedLink,
  }) async {
    final id = AssetType.parseAssetId(embedLink);
    return id != null ? AssetDbModel.db.find(id) : null;
  }
}
```

### 3. **AssetsBox** (`lib/core/databases/adapters/objectbox/assets_box.dart`)

âœ… Encoding/Decoding layer for JSON â†” Map conversion

- `modelToObject()`: AssetDbModel (Map) â†’ AssetObjectBox (JSON string)
  - Converts `AssetType` enum â†’ string (`type.name`)
  - Converts `metadata` Map â†’ JSON string
- `objectToModel()`: AssetObjectBox (JSON string) â†’ AssetDbModel (Map)
  - Converts string â†’ `AssetType` enum (`AssetType.fromValue()`)
  - Converts JSON string â†’ `metadata` Map

âœ… Query filtering by type and tags:

```dart
// Fetch only audio files
final audioAssets = await assetsBox.getAll(filters: {"type": AssetType.audio});

// Fetch only images (includes null for backward compatibility)
final images = await assetsBox.getAll(filters: {"type": AssetType.image});

// Filter by tag
final taggedAssets = await assetsBox.getAll(filters: {
  "type": AssetType.audio,
  "tag": tagId,
});

// Fetch by IDs
final assets = await assetsBox.getAll(filters: {"ids": [1, 2, 3]});
```

### 4. **InsertFileToDbService** (`lib/core/services/insert_file_to_db_service.dart`)

âœ… Extended with audio support:

```dart
// Original method for images
static Future<AssetDbModel?> insertImage(XFile file, Uint8List fileBytes)

// New method for audio
static Future<AssetDbModel?> insertAudio(
  String filePath,
  Uint8List fileBytes,
  {int? durationInMs}
) {
  // Stores in /audio/{timestamp}.m4a
  // Auto-captures duration in metadata
}
```

### 5. **Story Asset Extraction** (`lib/core/services/stories/story_extract_assets_from_content_service.dart`)

âœ… Service automatically extracts asset links from story content:

- Supports both `storypad://assets/` (images) and `storypad://audio/` (audio)
- Uses `AssetType` enum for scheme-based extraction
- Universal embed discovery (works with any future embed type)
- Internally uses `AssetLinkParser` utility for Quill Delta parsing

```dart
// Get all image links
final imageLinks = StoryExtractAssetsFromContentService.images(content);
// Returns: ["storypad://assets/123", ...]

// Get all audio links
final audioLinks = StoryExtractAssetsFromContentService.audio(content);
// Returns: ["storypad://audio/456", ...]

// Get all asset links
final allLinks = StoryExtractAssetsFromContentService.all(content);
// Returns: ["storypad://assets/123", "storypad://audio/456", ...]
```

### 6. **Platform Permissions** âœ…

**iOS** (`ios/Runner/Info.plist`):

```xml
<key>NSMicrophoneUsageDescription</key>
<string>This app needs access to your microphone to record voice notes for your stories.</string>
```

**Android** (`android/app/src/main/AndroidManifest.xml`):

```xml
<uses-permission android:name="android.permission.RECORD_AUDIO" />
<uses-permission android:name="android.permission.MODIFY_AUDIO_SETTINGS" />
```

**Dependencies** (`pubspec.yaml`):

```yaml
record: ^6.1.2 # Cross-platform recording
```

---

## ğŸ’¾ Metadata Storage Pattern

### Flexible Design (No Schema Migrations)

**Current (Audio Duration):**

```dart
metadata = {'durationInMs': 120000}
```

**Future (Transcription):**

```dart
metadata = {
  'durationInMs': 120000,
  'transcription': 'Hello, this is my voice journal entry'
}
```

**Future (Waveform Visualization):**

```dart
metadata = {
  'durationInMs': 120000,
  'waveform': [0.1, 0.2, 0.5, 0.3, ...]
}
```

**Why this works:**

- Database stores metadata as JSON string (flexible)
- Application layer uses Map (easy to manipulate)
- Add new fields without migrations
- Type-safe getters on AssetDbModel
- Backward compatible with existing images

---

## ğŸ·ï¸ Asset Tagging System

### Automatic Tag Assignment

Voice recordings automatically inherit tags from their connected stories:

**Implementation (`database_initializer.dart:35` & `stories_box.dart:182`):**

```dart
// When a story is saved (StoriesBox#set)
if (saved != null && !saved.draftStory) {
  // Get all assets used in this story
  List<AssetDbModel> assets = await AssetDbModel.db
      .where(filters: {'ids': saved.assets})
      .then((e) => e?.items ?? []);

  // Compute tags for each asset
  for (int i = 0; i < assets.length; i++) {
    Set<int> tags = await computeStoriesTagsForAsset(assets[i]);
    await assets[i].copyWith(tags: tags.toList()).save();
  }
}

// computeStoriesTagsForAsset(): Finds all stories using this asset
// and collects their unique tags
Future<Set<int>> computeStoriesTagsForAsset(AssetDbModel asset) async {
  return await buildQuery(filters: {'asset': asset.id})
      .build()
      .findAsync()
      .then((stories) => stories.map((s) => s.tags).expand((tags) => tags));
}
```

**Migration for existing assets (`database_initializer.dart`):**

```dart
static Future<void> computeStoryTagsForAsset() async {
  bool initialComputed = await ComputedInitialTagsForAssetsStorage().read();

  if (!initialComputed) {
    var assets = await AssetDbModel.db.where();
    for (var asset in assets) {
      var tags = await StoryDbModel.db.computeStoriesTagsForAsset(asset);
      await asset.copyWith(tags: tags.toList()).save();
    }
    await ComputedInitialTagsForAssetsStorage().write(true);
  }
}
```

**Why this matters:**

- ğŸ¯ **Organize recordings by topic** - Tag "Work" stories, all voice notes get "Work" tag
- ğŸ” **Powerful filtering** - View all "Travel" voice notes across all trips
- ğŸ”„ **Automatic updates** - Tags sync whenever stories are published (not drafts)
- ğŸ“Š **Zero manual work** - Users don't manage asset tags separately

---

## ğŸ“± Voice Journal UI (COMPLETE)

### Library View with Tabs (`library_view.dart`)

```dart
DefaultTabController(
  length: 2,
  child: Scaffold(
    appBar: AppBar(
      title: Text("Library"),
      bottom: TabBar(
        tabs: [
          Tab(icon: Icon(SpIcons.photo)),   // Images tab
          Tab(icon: Icon(SpIcons.voice)),   // Voice tab â† NEW
        ],
      ),
    ),
    body: TabBarView(
      children: [
        _ImagesTabContent(),
        _VoicesTabContent(),  // â† Voice journaling interface
      ],
    ),
  ),
)
```

### Voices Tab Content (`voices_tab_content.dart`)

**Features:**

âœ… **Tag Filtering** - Horizontal scrollable chips with story counts  
âœ… **Grouped by Date** - "Today", "Yesterday", or date (YYYY-MM-DD)  
âœ… **Cloud Backup Status** - Visual indicators for Google Drive sync  
âœ… **Quick Playback** - Tap to play in bottom sheet  
âœ… **Story Navigation** - View connected stories from context menu  
âœ… **Smart Deletion** - Delete locally or from Google Drive

**UI Structure:**

```dart
class _VoicesTabContent extends StatefulWidget {
  // State management
  CollectionDbModel<AssetDbModel>? assets;
  Map<int, int> storiesCount;  // asset_id â†’ story_count
  int? selectedTagId;

  // Dynamic filters
  Map<String, dynamic> get filters => {
    'type': AssetType.audio,
    'tag': selectedTagId,  // null = show all
  };

  // Real-time updates
  void initState() {
    StoryDbModel.db.addGlobalListener(_listener);
    _load();
  }

  Future<void> _load() async {
    // Fetch filtered audio assets
    assets = await AssetDbModel.db.where(filters: filters);

    // Get story counts for each asset
    storiesCount = StoryDbModel.db.getStoryCountByAssets(
      assetIds: assets.items.map((e) => e.id).toList(),
    );
  }
}
```

**Tag Filter UI:**

```dart
SpScrollableChoiceChips<TagDbModel>(
  choices: tagsProvider.tags.items,
  storiesCount: (tag) => tag.id == selectedTagId ? assets.length : null,
  toLabel: (tag) => tag.title,
  selected: (tag) => selectedTagId == tag.id,
  onToggle: (tag) {
    selectedTagId = selectedTagId == tag.id ? null : tag.id;
    _load();  // Re-fetch with new filter
  },
)
```

**Voice Item Display:**

```dart
ListTile(
  onTap: () => SpVoicePlaybackSheet(asset: asset).show(context),
  leading: Icon(SpIcons.voice),
  title: Text("3:45 PM ğŸŸ¢"),  // Time + backup status
  subtitle: Row(
    children: [
      Text("02:34"),  // Duration from metadata
      if (storyCount == 0) Icon(SpIcons.archive),  // Unused warning
    ],
  ),
  trailing: PopupMenu([
    if (storyCount > 0) "View Story",
    "Info",
    if (storyCount == 0) "Delete",
  ]),
)
```

**Date Grouping Logic:**

```dart
List<Map<String, dynamic>> _groupAssetsByDay(List<AssetDbModel> assets) {
  final grouped = <String, List<AssetDbModel>>{};

  for (var asset in assets) {
    final key = _getDayKey(asset.createdAt);  // "Today", "Yesterday", or date
    grouped.putIfAbsent(key, () => []).add(asset);
  }

  // Sort newest first
  return grouped.entries
      .sortedBy((e) => _parseDateKey(e.key))
      .map((e) => {'label': e.key, 'assets': e.value})
      .toList();
}
```

### Voice Playback Sheet (`sp_voice_playback_sheet.dart`)

**Modal bottom sheet with audio player:**

```dart
class SpVoicePlaybackSheet extends BaseBottomSheet {
  final AssetDbModel asset;

  Widget build(BuildContext context) {
    return SpAudioPlayer(
      autoplay: true,
      initialDuration: Duration(milliseconds: asset.durationInMs),
      onDownloadRequested: () => _downloadFromGoogleDrive(asset),
    );
  }
}
```

### Audio Player Widget (`sp_audio_player.dart`)

**Reusable player with lifecycle management:**

```dart
class SpAudioPlayer extends StatefulWidget {
  final String? filePath;  // Local path
  final Duration? initialDuration;
  final Future<String> Function()? onDownloadRequested;  // Lazy-load callback
  final bool autoplay;

  // Features:
  // âœ… Play/pause with progress slider
  // âœ… Current time / total duration display
  // âœ… Stadium-shaped clean design
  // âœ… Auto-pause on app background
  // âœ… Supports lazy-loading (download on play)
  // âœ… AudioPlayer lifecycle management
}
```

### Asset Deletion (`library_view_model.dart`)

**Smart deletion logic:**

```dart
Future<void> deleteAsset(AssetDbModel asset, int storyCount) async {
  // Safety checks
  if (storyCount > 0) return;  // Can't delete if used in stories
  if (!hasInternet) return showSnackBar("No internet");

  // Confirm with user
  if (await showOkCancelDialog(...) == OkCancelResult.ok) {
    // Delete from Google Drive if backed up
    if (asset.isGoogleDriveUploadedFor(currentUser.email)) {
      await googleDriveClient.deleteFile(fileId);
    }

    // Delete local file and database entry
    await asset.delete();
  }
}
```

---

## ğŸ”„ Data Flow

### Recording & Saving (IMPLEMENTED âœ…)

```
1. User taps record button
   â†“
2. VoiceRecorderService.startRecording(outputPath)
   â†“
3. Records audio to /audio/{timestamp}.m4a
   â†“
4. VoiceRecorderService.stopRecording()
   â†’ Returns VoiceRecordingResult(path, durationInMs)
   â†“
5. InsertFileToDbService.insertAudio(
     filePath, fileBytes, durationInMs
   )
   â†“
6. Creates AssetDbModel with:
   â€¢ type: AssetType.audio (enum)
   â€¢ metadata: {'durationInMs': 120000}
   â€¢ localFilePath: ".../audio/..." (via type.getStoragePath())
   â†“
7. asset.save() â†’ ObjectBox (type converted to 'audio' string)
   â†“
8. Embed in Quill: BlockEmbed.audio(asset.embedLink)
   â†’ asset.embedLink uses type.buildEmbedLink(id)
   â†’ Creates "storypad://audio/123"
   â†“
9. Story.assets collection updated via StoryExtractAssetsFromContentService
   â†“
10. Asset automatically queued for Google Drive backup
```

### Playing Back (IMPLEMENTED âœ…)

**From Library:**

```
User taps voice item in Library â†’ Voices tab
  â†“
SpVoicePlaybackSheet opens (bottom sheet)
  â†“
SpAudioPlayer widget renders
  â†“
If file exists locally:
  â†’ Load from asset.localFilePath
  â†“
Else (cloud-only):
  â†’ Call onDownloadRequested callback
  â†’ GoogleDriveAssetDownloaderService.downloadAsset()
  â†’ Returns downloaded file path
  â†“
AudioPlayer.setFilePath(path)
  â†“
Autoplay: true â†’ Starts playback immediately
  â†“
User controls: play/pause, seek, see duration
  â†“
Sheet dismissible anytime
```

**From Story (Quill Editor):**

```
Quill Editor renders SpAudioBlockEmbed
  â†“
Display: [â–¶] Duration (MM:SS)
  â†“
Tap to play inline
  â†“
Load audio from asset.localFilePath
  â†“
JustAudio player handles playback
  â†“
Continue journaling while audio plays in background
```

### Backup to Google Drive (IMPLEMENTED âœ…)

```
Same mechanism as images:
1. InsertFileToDbService marks asset.needBackup = true
   â†“
2. BackupService detects new audio asset
   â†“
3. Uploads .m4a file to Google Drive
   â†“
4. Updates asset.cloudDestinations:
   cloudDestinations['google_drive'][email] = {
     'file_id': 'drive_file_id',
     'file_name': '1701234568000.m4a'
   }
   â†“
5. UI shows backup status badge:
   ğŸŸ¡ Warning (not backed up)
   ğŸŸ¢ Success (backed up)
   â†“
6. If local file deleted, can re-download from cloud
```

### Tag Updates (IMPLEMENTED âœ…)

```
User publishes story with voice note + "Travel" tag
  â†“
StoriesBox#set() triggered
  â†“
Extract story.assets (list of asset IDs)
  â†“
For each asset:
  â†“
  Query all stories using this asset
  â†“
  Collect unique tags from all stories
  â†“
  asset.copyWith(tags: [1, 5, 12]).save()
  â†“
Library â†’ Voices tab now shows "Travel" filter chip
  â†“
User selects "Travel" â†’ Only shows this voice note
```

---

## âœ¨ Why Users Will Pay $1.99

1. **Emotional Connection** - Hear your own voice in past entries
2. **Accessibility** - For people who prefer speaking to typing
3. **Memory Fidelity** - Tone, emotion, pauses preserved in recordings
4. **Quick Capture** - Record thoughts faster than typing
5. **Private Journaling** - Intimate audio format for personal reflection
6. **Complementary** - Pairs well with Relaxing Sounds add-on
7. **Smart Organization** - Auto-tagging keeps voice notes organized
8. **Seamless Backup** - Never lose precious voice memories
9. **Cross-device Sync** - Access voice journals from any device

---

## ğŸ‰ User Experience (LIVE IN PRODUCTION)

### Recording a Voice Note

```
1. Open story editor
2. Tap microphone button in toolbar
3. Record your thoughts (speak naturally)
4. Tap stop â†’ Voice note embedded in story
5. Publish story â†’ Voice gets auto-tagged
6. Background sync to Google Drive
```

### Browsing Voice Journal Library

```
1. Tap Library tab (bottom navigation)
2. Select "Voice" tab (ğŸ¤ icon)
3. See all recordings grouped by date:
   ğŸ“… Today
      ğŸ¤ 3:45 PM - 02:34 ğŸŸ¢
      ğŸ¤ 9:12 AM - 01:15 ğŸŸ¢
   ğŸ“… Yesterday
      ğŸ¤ 7:30 PM - 03:21 ğŸŸ¢
   ğŸ“… 2025-11-06
      ğŸ¤ 2:15 PM - 00:45 ğŸŸ¡ (backing up...)

4. Filter by tags (horizontal chips):
   [All] [Work 3] [Travel 5] [Personal 12]

5. Tap to play immediately
6. Long-press for options:
   â€¢ View connected story
   â€¢ Asset info (size, date, backup status)
   â€¢ Delete (if unused in stories)
```

### Playback Experience

```
Tap voice item
  â†“
Bottom sheet slides up
  â†“
Audio player appears:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   â–¶  â”â”â”â”â—â”â”â”â”â”â”â”â”  02:34  â”‚
  â”‚      00:34        Total     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
Auto-plays immediately
  â†“
Drag slider to seek
  â†“
Dismiss sheet anytime (playback stops)
```

### Tag-Based Organization

```
User journey:
  â†“
Create "Work Meeting" story
  â†“
Record voice note during meeting
  â†“
Add tags: #Work #Team #Q4
  â†“
Publish story
  â†“
Voice note automatically gets tags: Work, Team, Q4
  â†“
Later: Filter Library by "Work" â†’ See all work-related voices
```

---

## âœ… Implementation Status

### Phase 1: Core Recording âœ… COMPLETE

- âœ… `VoiceRecorderService` wrapper around `record` package
- âœ… `SpAudioBlockEmbed` widget for inline playback in stories
- âœ… `SpAudioPlayer` reusable audio player widget
- âœ… Recording button in Quill toolbar
- âœ… Start/stop/save recording flow
- âœ… End-to-end: record â†’ embed â†’ play â†’ backup
- âœ… Google Drive backup for audio files
- âœ… Library tab with voice recordings list
- âœ… Tag-based filtering
- âœ… Date-grouped organization
- âœ… Cloud sync status indicators
- âœ… Delete from local & Google Drive

### Phase 2: Enhanced UX (Future)

- [ ] Waveform visualization during playback
- [ ] Pause/resume during recording
- [ ] Trim recordings
- [ ] Audio level meter during recording
- [ ] Re-record option
- [ ] Voice note thumbnails/previews

### Phase 3: Smart Features (Future - Premium Tier)

- [ ] Auto-transcription (Whisper API / On-device)
- [ ] Transcription editing UI
- [ ] Sentiment detection from voice
- [ ] Voice-to-text search indexing
- [ ] AI-powered voice summaries
- [ ] Speaker identification (multi-person journals)

---

## ï¿½ Key Files

| File                                             | Purpose                                        |
| ------------------------------------------------ | ---------------------------------------------- |
| `asset_type.dart`                                | **NEW**: AssetType enum with URI/storage logic |
| `entities.dart`                                  | Added `type` and `metadata` to AssetObjectBox  |
| `asset_db_model.dart`                            | Asset model with AssetType enum, audio getters |
| `assets_box.dart`                                | JSON encoding/decoding, type filtering         |
| `insert_file_to_db_service.dart`                 | Audio file insertion method                    |
| `story_extract_assets_from_content_service.dart` | Universal asset link extraction                |
| `asset_link_parser.dart`                         | Utility for parsing Quill Delta embed links    |
| `database_initializer.dart`                      | Asset tag migration & initialization           |
| `stories_box.dart`                               | Auto-compute tags for assets on story save     |
| `library_view.dart`                              | Main library with Images/Voice tabs            |
| `voices_tab_content.dart`                        | Voice recordings list with tag filters         |
| `sp_voice_playback_sheet.dart`                   | Modal bottom sheet for playback                |
| `sp_audio_player.dart`                           | Reusable audio player widget                   |
| `library_view_model.dart`                        | Delete asset logic (local + cloud)             |
| `sp_scrollable_choice_chips.dart`                | Tag filter chips with counts                   |
| `ios/Runner/Info.plist`                          | Microphone permission                          |
| `android/AndroidManifest.xml`                    | Microphone permissions                         |
| `pubspec.yaml`                                   | `record: ^6.1.2`, `just_audio` dependencies    |
